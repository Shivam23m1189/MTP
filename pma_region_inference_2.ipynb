{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a9ab14c-1f43-4e1e-a51b-20cd5ce29435",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint provided!\n",
      "2025-09-12 16:09:23,163 [INFO] - Loading model: /home/shivam/nuc_seg/CellViT-plus-plus-main/checkpoints/CellViT-Virchow-x40-AMP-001.pth\n",
      "No checkpoint provided!\n",
      "2025-09-12 16:09:28,995 [INFO] - <All keys matched successfully>\n",
      "2025-09-12 16:09:33,284 [INFO] - Based on the hardware we limit the batch size to a maximum of:\n",
      "2025-09-12 16:09:33,285 [INFO] - 8\n",
      "2025-09-12 16:09:33,286 [INFO] - Loading inference transformations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12 16:09:37,264\tINFO worker.py:1724 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-12 16:09:42,217 [INFO] - Using 4 ray-workers\n",
      "Found 1 region folders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing folders:   0%|                                 | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 10 images in CAIB-T00001394OP01B01P0101HE_10_regions\n",
      "Processing region: CAIB-T00001394OP01B01P0101HE_x29927_y126730\n",
      "2025-09-12 16:10:28,003 [INFO] - Initializing Cell-Postprocessor\n",
      "2025-09-12 16:10:28,010 [INFO] - Finding edge-cells for merging\n",
      "2025-09-12 16:10:28,029 [INFO] - Removal of cells detected multiple times\n",
      "2025-09-12 16:10:28,063 [INFO] - Iteration 0: Found overlap of # cells: 7\n",
      "2025-09-12 16:10:28,094 [INFO] - Iteration 1: Found overlap of # cells: 0\n",
      "2025-09-12 16:10:28,095 [INFO] - Found all overlapping cells\n",
      "Processing region: CAIB-T00001394OP01B01P0101HE_x7980_y10976\n",
      "2025-09-12 16:10:53,454 [INFO] - Initializing Cell-Postprocessor\n",
      "2025-09-12 16:10:53,459 [INFO] - Finding edge-cells for merging\n",
      "2025-09-12 16:10:53,466 [INFO] - Removal of cells detected multiple times\n",
      "2025-09-12 16:10:53,469 [INFO] - Iteration 0: Found overlap of # cells: 0\n",
      "2025-09-12 16:10:53,469 [INFO] - Found all overlapping cells\n",
      "Processing region: CAIB-T00001394OP01B01P0101HE_x11971_y126730\n",
      "2025-09-12 16:11:29,795 [INFO] - Initializing Cell-Postprocessor\n",
      "2025-09-12 16:11:29,800 [INFO] - Finding edge-cells for merging\n",
      "2025-09-12 16:11:29,817 [INFO] - Removal of cells detected multiple times\n",
      "2025-09-12 16:11:29,853 [INFO] - Iteration 0: Found overlap of # cells: 9\n",
      "2025-09-12 16:11:29,887 [INFO] - Iteration 1: Found overlap of # cells: 0\n",
      "2025-09-12 16:11:29,889 [INFO] - Found all overlapping cells\n",
      "Processing region: CAIB-T00001394OP01B01P0101HE_x36910_y126730\n",
      "Error processing CAIB-T00001394OP01B01P0101HE_x36910_y126730: list index out of range\n",
      "Processing region: CAIB-T00001394OP01B01P0101HE_x17956_y7983\n",
      "Error processing CAIB-T00001394OP01B01P0101HE_x17956_y7983: list index out of range\n",
      "Processing region: CAIB-T00001394OP01B01P0101HE_x8978_y25944\n",
      "Error processing CAIB-T00001394OP01B01P0101HE_x8978_y25944: list index out of range\n",
      "Processing region: CAIB-T00001394OP01B01P0101HE_x44891_y9978\n",
      "Error processing CAIB-T00001394OP01B01P0101HE_x44891_y9978: list index out of range\n",
      "Processing region: CAIB-T00001394OP01B01P0101HE_x15961_y135711\n",
      "Error processing CAIB-T00001394OP01B01P0101HE_x15961_y135711: list index out of range\n",
      "Processing region: CAIB-T00001394OP01B01P0101HE_x42896_y113758\n",
      "Error processing CAIB-T00001394OP01B01P0101HE_x42896_y113758: list index out of range\n",
      "Processing region: CAIB-T00001394OP01B01P0101HE_x12968_y24946\n",
      "Error processing CAIB-T00001394OP01B01P0101HE_x12968_y24946: list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing folders: 100%|████████████████████████| 1/1 [06:07<00:00, 367.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All regions processed successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import ujson\n",
    "import ray\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import Union\n",
    "\n",
    "# Import your CellViT modules\n",
    "from cellvit.models.cell_segmentation.cellvit_virchow import CellViTVirchow\n",
    "from cellvit.utils.tools import unflatten_dict\n",
    "from cellvit.inference.inference_disk import CellViTInference\n",
    "from cellvit.inference.postprocessing_cupy import (\n",
    "    BatchPoolingActor,\n",
    "    DetectionCellPostProcessorCupy,\n",
    ")\n",
    "from cellvit.config.config import TYPE_NUCLEI_DICT_PANNUKE\n",
    "\n",
    "class region_dataset(Dataset):\n",
    "    def __init__(self, image_path, transform=None, patch_size=256, overlap = 32):\n",
    "        img_bgr = cv2.imread(image_path)\n",
    "        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "        self.img_np = np.array(img_rgb)\n",
    "        self.patch_size = patch_size\n",
    "        self.region_coords = []\n",
    "        self.transform = transform\n",
    "        h, w, _ = self.img_np.shape\n",
    "        h = h-256\n",
    "        w = w-256\n",
    "        self.overlap = overlap\n",
    "        self.shift = self.patch_size - self.overlap\n",
    "        for i in range(0, h, self.shift):\n",
    "            # if i + self.patch_size > h:\n",
    "            #     i = max(0, h - self.patch_size)\n",
    "            for j in range(0, w, self.shift):\n",
    "                # if j + self.patch_size > w:\n",
    "                    # j = max(0, w - self.patch_size)\n",
    "                self.region_coords.append((i, j))\n",
    "                # if j + self.shift >= w:\n",
    "                    # break\n",
    "            # if i + self.shift >= h:\n",
    "                # break\n",
    "    def __len__(self):\n",
    "        return len(self.region_coords)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.region_coords[idx]\n",
    "        patch = self.img_np[x:min(x + self.patch_size, self.img_np.shape[0]),\n",
    "                            y:min(y + self.patch_size, self.img_np.shape[1])]\n",
    "        \n",
    "        # Pad if necessary\n",
    "        # if patch.shape[0] < self.patch_size or patch.shape[1] < self.patch_size:\n",
    "        #     patch = np.pad(patch, \n",
    "        #                   ((0, self.patch_size - patch.shape[0]), \n",
    "        #                    (0, self.patch_size - patch.shape[1]), \n",
    "        #                    (0, 0)), \n",
    "        #                   mode='constant')\n",
    "        \n",
    "        if self.transform:\n",
    "            patch = self.transform(patch)\n",
    "        \n",
    "        metadata = {\n",
    "            \"col\": y // self.shift,\n",
    "            \"row\": x // self.shift,\n",
    "            \"position_x\": x,\n",
    "            \"position_y\": y,\n",
    "        }\n",
    "    \n",
    "        return patch, metadata\n",
    "\n",
    "@dataclass\n",
    "class WSIMetadata:\n",
    "    slide_path: Union[str, Path]\n",
    "    metadata: dict\n",
    "\n",
    "def get_wsi_metadata(image_path, patch_size=256, downsample=1, patch_overlap=32, label_map=None, normalize_stains=False):\n",
    "    # Get image dimensions\n",
    "    img = cv2.imread(image_path)\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    shift_size = patch_size - patch_overlap\n",
    "    \n",
    "    # n_cols = math.ceil((w - patch_size) / shift_size) + 1 if w > patch_size else 1\n",
    "    # n_rows = math.ceil((h - patch_size) / shift_size) + 1 if h > patch_size else 1\n",
    "    \n",
    "    n_cols = 4 #math.ceil(w / patch_size)\n",
    "    n_rows = 4 #math.ceil(h / patch_size)\n",
    "    \n",
    "    slide_mag = 40  \n",
    "    slide_mpp = 0.25  \n",
    "    resulting_mpp = slide_mpp * downsample\n",
    "\n",
    "    wsi_metadata = {\n",
    "        \"orig_n_tiles_cols\": n_cols,\n",
    "        \"orig_n_tiles_rows\": n_rows,\n",
    "        \"base_magnification\": slide_mag,\n",
    "        \"downsampling\": downsample,\n",
    "        \"label_map\": label_map if label_map is not None else {},\n",
    "        \"patch_overlap\": patch_overlap,\n",
    "        \"patch_size\": patch_size,\n",
    "        \"base_mpp\": slide_mpp,\n",
    "        \"target_patch_mpp\": resulting_mpp,\n",
    "        \"stain_normalization\": normalize_stains,\n",
    "        \"magnification\": slide_mag / (downsample * 1.0),\n",
    "        \"level\": 8,\n",
    "    }\n",
    "\n",
    "    return wsi_metadata\n",
    "\n",
    "def default_collate_fn(batch):\n",
    "    patches = []\n",
    "    metadatas = []\n",
    "    for patch, metadata in batch:\n",
    "        patches.append(patch)\n",
    "        metadatas.append(metadata)\n",
    "    return torch.stack(patches), metadatas\n",
    "\n",
    "def process_single_region(image_path, model, device, run_conf, infer_cell, batch_size=8, overlap=32):  # Reduced further\n",
    "    \"\"\"Process a single region image and save GeoJSON results\"\"\"\n",
    "    \n",
    "    image_path_obj = Path(image_path)\n",
    "    output_dir = image_path_obj.parent\n",
    "    region_name = image_path_obj.stem\n",
    "    \n",
    "    geojson_path = output_dir / f\"{region_name}_cells.geojson\"\n",
    "    # Uncomment to skip existing files\n",
    "    # if geojson_path.exists():\n",
    "    #     print(f\"Skipping {region_name}, GeoJSON already exists\")\n",
    "    #     return\n",
    "    \n",
    "    print(f\"Processing region: {region_name}\")\n",
    "    \n",
    "    # Setup transforms and dataset\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    dataset = region_dataset(image_path=image_path, transform=transform, patch_size=256,overlap=overlap )\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size, num_workers=0, \n",
    "                           collate_fn=default_collate_fn, pin_memory=True)\n",
    "\n",
    "    wsi_metadata = get_wsi_metadata(\n",
    "        image_path=image_path,\n",
    "        patch_size=256,\n",
    "        downsample=1,\n",
    "        patch_overlap= overlap,  \n",
    "        label_map={\"tumor\": 1, \"normal\": 0},\n",
    "        normalize_stains=False,\n",
    "    )\n",
    "    wsi = WSIMetadata(\n",
    "        slide_path=image_path,\n",
    "        metadata=wsi_metadata,\n",
    "    )\n",
    "\n",
    "    postprocessor = DetectionCellPostProcessorCupy(\n",
    "        wsi=wsi,\n",
    "        nr_types=run_conf[\"data\"][\"num_nuclei_classes\"],\n",
    "        resolution=0.25,\n",
    "        classifier=None, \n",
    "        binary=False,\n",
    "    )\n",
    "\n",
    "    # Use fewer ray actors to avoid resource contention\n",
    "    ray_actors = min(2, batch_size)  # Reduced from 4-8 to max 2\n",
    "    \n",
    "    try:\n",
    "        # Initialize ray once with appropriate resources\n",
    "        if not ray.is_initialized():\n",
    "            ray.init(num_cpus=ray_actors, num_gpus=0.1, ignore_reinit_error=True)\n",
    "        \n",
    "        batch_pooling_actors = [\n",
    "            BatchPoolingActor.remote(postprocessor, run_conf)\n",
    "            for _ in range(ray_actors)\n",
    "        ]\n",
    "        \n",
    "        call_ids = []\n",
    "        with torch.inference_mode():\n",
    "            for batch_num, (patches, metadata) in enumerate(dataloader):\n",
    "                batch_actor = batch_pooling_actors[batch_num % ray_actors]\n",
    "                patches = patches.to(device, non_blocking=True)\n",
    "                \n",
    "                predictions = model(patches, retrieve_tokens=True)\n",
    "                predictions = infer_cell.apply_softmax_reorder(predictions=predictions)\n",
    "                predictions = {k: v.cpu() if isinstance(v, torch.Tensor) else v \n",
    "                              for k, v in predictions.items()}\n",
    "                \n",
    "                call_id = batch_actor.convert_batch_to_graph_nodes.remote(predictions, metadata)\n",
    "                call_ids.append(call_id)\n",
    "\n",
    "            # Process results in smaller chunks to avoid memory issues\n",
    "            inference_results = []\n",
    "            for i in range(0, len(call_ids), 4):  # Process 4 at a time\n",
    "                chunk = call_ids[i:i+4]\n",
    "                inference_results.extend(ray.get(chunk))\n",
    "\n",
    "        # Result processing\n",
    "        cell_dict_wsi = []\n",
    "        cell_dict_detection = []\n",
    "        \n",
    "        label_map = TYPE_NUCLEI_DICT_PANNUKE \n",
    "        label_map = {int(k): v for k, v in label_map.items()}\n",
    "        \n",
    "        graph_data = {\n",
    "            \"cell_tokens\": [],\n",
    "            \"positions\": [],\n",
    "            \"metadata\": {\n",
    "                \"wsi_metadata\": wsi.metadata,\n",
    "                \"nuclei_types\": label_map,\n",
    "            },\n",
    "        }\n",
    "        \n",
    "        for batch_results in inference_results:\n",
    "            (\n",
    "                batch_complete_dict,\n",
    "                batch_detection,\n",
    "                batch_cell_tokens,\n",
    "                batch_cell_positions,\n",
    "            ) = batch_results\n",
    "            \n",
    "            cell_dict_wsi.extend(batch_complete_dict)\n",
    "            cell_dict_detection.extend(batch_detection)\n",
    "            graph_data[\"cell_tokens\"].extend(batch_cell_tokens)\n",
    "            graph_data[\"positions\"].extend(batch_cell_positions)\n",
    "\n",
    "        keep_idx = infer_cell._post_process_edge_cells(cell_list=cell_dict_wsi)\n",
    "        cell_dict_wsi = [cell_dict_wsi[idx_c] for idx_c in keep_idx]\n",
    "        cell_dict_detection = [cell_dict_detection[idx_c] for idx_c in keep_idx]\n",
    "        graph_data[\"cell_tokens\"] = [graph_data[\"cell_tokens\"][idx_c] for idx_c in keep_idx]\n",
    "        graph_data[\"positions\"] = [graph_data[\"positions\"][idx_c] for idx_c in keep_idx]\n",
    "        \n",
    "        final_cell_dict = {\n",
    "            \"wsi_metadata\": wsi.metadata,\n",
    "            \"type_map\": label_map,\n",
    "            \"cells\": cell_dict_wsi,  \n",
    "        }\n",
    "        \n",
    "        # Save results\n",
    "        geojson_list = infer_cell._convert_json_geojson(final_cell_dict[\"cells\"], True)\n",
    "        \n",
    "        with open(geojson_path, \"w\") as outfile:\n",
    "            ujson.dump(geojson_list, outfile)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {region_name}: {str(e)}\")\n",
    "        # Create empty file on error to avoid reprocessing\n",
    "        with open(geojson_path, \"w\") as outfile:\n",
    "            ujson.dump([], outfile)\n",
    "    finally:\n",
    "        # Don't shutdown ray here - let the main function handle it\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "def main():\n",
    "    # Load model\n",
    "    model_path = \"/home/shivam/nuc_seg/CellViT-plus-plus-main/checkpoints/CellViT-Virchow-x40-AMP-001.pth\"\n",
    "    model_checkpoint = torch.load(model_path, map_location=\"cpu\")\n",
    "    run_conf = unflatten_dict(model_checkpoint[\"config\"], \".\")\n",
    "    \n",
    "    model = CellViTVirchow(\n",
    "        model_virchow_path=None,\n",
    "        num_nuclei_classes=run_conf[\"data\"][\"num_nuclei_classes\"],\n",
    "        num_tissue_classes=run_conf[\"data\"][\"num_tissue_classes\"]\n",
    "    )\n",
    "    model.load_state_dict(model_checkpoint[\"model_state_dict\"])\n",
    "    \n",
    "    device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    run_conf[\"model\"][\"token_patch_size\"] = model.patch_size\n",
    "    \n",
    "    infer_cell = CellViTInference(model_path=model_path, gpu=2)\n",
    "    \n",
    "    # Find all region folders\n",
    "    base_directory = \"/home/shivam/nuc_seg/CellViT-plus-plus-main/inference_data\"\n",
    "    region_folders = [f for f in os.listdir(base_directory) \n",
    "                  if os.path.isdir(os.path.join(base_directory,f)) and f.endswith(\"_10_regions\")]\n",
    "    \n",
    "    print(f\"Found {len(region_folders)} region folders\")\n",
    "    \n",
    "    try:\n",
    "        # Process all region images\n",
    "        for folder in tqdm(region_folders, desc=\"Processing folders\"):\n",
    "            folder_path = os.path.join(base_directory, folder)\n",
    "            image_files = glob.glob(os.path.join(folder_path, \"*.png\"))\n",
    "            \n",
    "            print(f\"Processing {len(image_files)} images in {folder}\")\n",
    "            \n",
    "            for image_path in image_files:\n",
    "                process_single_region(\n",
    "                    image_path=image_path,\n",
    "                    model=model,\n",
    "                    device=device,\n",
    "                    run_conf=run_conf,\n",
    "                    infer_cell=infer_cell,\n",
    "                    batch_size=8 \n",
    "                )\n",
    "    \n",
    "    finally:\n",
    "        # Clean up ray at the end\n",
    "        if ray.is_initialized():\n",
    "            ray.shutdown()\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    print(\"All regions processed successfully!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "513060ef-7bb5-4740-91cb-112341b0c8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done..!!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "def geojson_shift_handling(geojson_path):\n",
    "    with open(geojson_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    # min_x = float('inf')\n",
    "    # min_y = float('inf')\n",
    "    \n",
    "    # for feature in data:\n",
    "    #     for polygon_set in feature['geometry']['coordinates']:\n",
    "    #         for polygon in polygon_set:\n",
    "    #             for coord in polygon:\n",
    "    #                 min_x = min(min_x, coord[0]) # print(ring)\n",
    "    #                 min_y = min(min_y, coord[1])\n",
    "    min_x = -32\n",
    "    min_y = -32\n",
    "    x_shift = -min_x\n",
    "    y_shift = -min_y\n",
    "\n",
    "    for feature in data:\n",
    "        transformed_coords = []\n",
    "        for polygon_set in feature['geometry']['coordinates']:\n",
    "            transformed_polygons = []\n",
    "            for polygon in polygon_set:\n",
    "                transformed_poly = [[x + x_shift, y + y_shift] for x,y in polygon]\n",
    "                transformed_polygons.append(transformed_poly)\n",
    "            transformed_coords.append(transformed_polygons)\n",
    "        feature['geometry']['coordinates'] = transformed_coords\n",
    "\n",
    "    geojson_path_obj = Path(geojson_path)\n",
    "    output_dir = geojson_path_obj.parent\n",
    "    region_name = geojson_path_obj.stem\n",
    "    geojson_fixed_path = output_dir / f\"{region_name}_FIXED.geojson\"\n",
    "\n",
    "    with open(geojson_fixed_path, 'w') as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "\n",
    "base_directory = \"/home/shivam/nuc_seg/CellViT-plus-plus-main/inference_data\"\n",
    "region_folders = [f for f in os.listdir(base_directory) \n",
    "                  if os.path.isdir(os.path.join(base_directory,f)) and f.endswith(\"_10_regions\")]\n",
    "for folder in region_folders:\n",
    "    folder_path = os.path.join(base_directory, folder)\n",
    "    geojson_files = glob.glob(os.path.join(folder_path, \"*_cells.geojson\"))\n",
    "    for geojson_path in geojson_files:\n",
    "        geojson_shift_handling(geojson_path)\n",
    "\n",
    "print(\"done..!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf293fa-6def-4abd-b8d7-66dccf9d5212",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
